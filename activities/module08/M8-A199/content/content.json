{"content":[{"content":{"params":{"text":"<p dir=\"ltr\">A training kit, the right corpora, and a proper setting of parameters. After getting familiar with these three items, anyone should be able to train a neural custom engine. Following a recipe would even make it easier. Ready to cook? Let\u2019s go.&nbsp;<\/p>\n\n<p dir=\"ltr\">Imagine that you want to train an English-French MT system that is able to translate political content. We are going to use the following ingredients:<\/p>\n\n<p>&nbsp;<\/p>\n\n<ul>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Training kit: we are going to use MutNMT. This will allow us to train a custom MT system for didactical purposes, providing a 1-hour training slot and other features like the ability to translate texts and documents with our trained system, compare it to others or evaluate it with automatic metrics.&nbsp;<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Corpora: we want as much in-domain content as possible, parallel sentences with not only a good coverage of political matters, but also with a good coverage of language itself. That is, high-quality sentences, varied, consistent, representative of the content that will be translated using the trained MT system. Remember that we will have to split our corpus into three groups: training corpus, validation corpus and test corpus. We need to avoid overlap among these three groups. To this aim, we will use the following English-French corpora:<\/p>\n\n\t<ul>\n\t\t<li aria-level=\"2\" dir=\"ltr\">\n\t\t<p dir=\"ltr\" role=\"presentation\">JRC-Acquis as training corpus. It is made of selected texts from the collection of legislative texts of the European Union written between the 1950s and now. MutNMT will allow you to add up to 500,000 sentences as a training corpus.&nbsp;<\/p>\n\t\t<\/li>\n\t\t<li aria-level=\"2\" dir=\"ltr\">\n\t\t<p dir=\"ltr\" role=\"presentation\">EUconst (half as validation and half as test corpus). It is \u200b\u200ba parallel corpus collected from the European Constitution. MutNMT will allow you to add up to 5,000 sentences as a validation and test corpus.&nbsp;&nbsp;<\/p>\n\t\t<\/li>\n\t<\/ul>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Parameters: MutNMT will allow you to set the most commonly used parameters before launching your training. Default values are already provided, but we will change these a bit.<\/p>\n\t<\/li>\n<\/ul>\n\n<p>&nbsp;<\/p>\n\n<p dir=\"ltr\">Now, the recipe goes like this:&nbsp;<\/p>\n\n<p>&nbsp;<\/p>\n\n<ul>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Access MutNMT (ask your tutor to provide a link)<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Take a look at the above-mentioned corpora in the Data section. These should already be available on MutNMT. Preview them using the option under the three dots menu on the list of corpora in the Data section. If these are not available, try to find the TMX versions at OPUS and upload them yourself or ask your tutor to do so.&nbsp;&nbsp;<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Go to the Train section: take a look at the parameters and corpus selector and try to understand them. To this aim, take Nile\u2019s Tour clicking on \u201cNile, please help\u201d on the left menu of the screen. During the tour, note the ranges recommended for the following parameters: vocabulary size, beam size, batch size, validation frequency, stopping condition, duration.<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Add training details: engine name, language combination (English-French), a description of your system, and set the parameters to: vocabulary size (16000), beam size (8), batch size (6000), validation frequency (3000), stopping condition(5), duration (10). We are setting one of the parameters out of the recommended ranges: batch size. If you need to refresh your mind, hover over the text field to get an explanation.&nbsp;<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Add corpora using the corpus selector. Below the columns for each type of corpus you will find a list with all the corpora available for the set language combination. You can scroll down to see them all. For Training corpus, look for JRC-aquis, note that the size in number of sentences is 503,436. Use the plus sign (+) to add it to your training. You will see that the corpus will appear in the above empty box. Just 500,000 sentences will be used as this is the max. allowed in MutNMT, the rest of corpus sentences (3,436) will disappear from the Train corpus selector but will be available in the other two selectors (Validation and Test). We will not use them for this purpose. Indeed, for Validation we will use a portion of the EUconst corpus. Exactly, 3664 sentences. Choose this number of sentences in the corpus selector where you see the number of sentences, then click on the plus sign. The rest of the EUconst corpus will be used as a Test corpus. Just click on the plus sign under the test corpus selector.<\/p>\n\t<\/li>\n<\/ul>\n\n<p>&nbsp;<\/p>\n\n<p dir=\"ltr\">We are ready to train our custom English-French politics-savvy engine. Your screen at this point should look like this:<\/p>\n"},"library":"H5P.AdvancedText 1.1","metadata":{"contentType":"Text","license":"U","title":"Untitled Text","defaultLanguage":"en"},"subContentId":"10d1315d-e498-45c4-a689-defd4256b0e6"},"useSeparator":"disabled"},{"content":{"params":{"contentName":"Image","file":{"path":"images\/file-61a51219b337a.png","mime":"image\/png","copyright":{"license":"U"},"width":1202,"height":777}},"library":"H5P.Image 1.1","metadata":{"contentType":"Image","license":"U","title":"Untitled Image","defaultLanguage":"en"},"subContentId":"784a9491-b2ca-4702-bec5-bc3faf1df819"},"useSeparator":"disabled"},{"content":{"params":{"contentName":"Image","file":{"path":"images\/file-61a5122a20e4d.png","mime":"image\/png","copyright":{"license":"U"},"width":1225,"height":346}},"library":"H5P.Image 1.1","metadata":{"contentType":"Image","license":"U","title":"Untitled Image","defaultLanguage":"en"},"subContentId":"43bd82ba-d893-4b68-b074-2781172ac471"},"useSeparator":"auto"},{"content":{"params":{"text":"<p dir=\"ltr\">Now, if you are allowed to train, just click on the Start Training button. Please stay on the launching screen for a couple of minutes (the time needed to launch the engine). If you close it, your training will not be launched and your settings will be lost. If you are not allowed to train, keep reading.&nbsp;<\/p>\n\n<p dir=\"ltr\">As soon as the training is launched, you will start seeing a living training log where you will be able to monitor many things. First, you have a summary of the engine settings, corpora and stats, time and energy consumption. It is followed by a test zone (only available after training is completed). Then, you will see a dashboard with four plots showing progress of the training process of the translation model. It shows the learning curves representing training and validation loss (used as model optimization scores), learning rate and BLEU scores (used as a model performance score). Finally, a detailed training log is provided for each validation point (3,000 steps in our example) including: time, epoch, step, batch loss (for training), tokens and learning rate.<\/p>\n"},"library":"H5P.AdvancedText 1.1","metadata":{"contentType":"Text","license":"U","title":"Untitled Text","defaultLanguage":"en"},"subContentId":"68d46417-6240-440d-ac2d-f9a20b2dbe56"},"useSeparator":"enabled"},{"content":{"params":{"contentName":"Image","file":{"path":"images\/file-61a512e436515.png","mime":"image\/png","copyright":{"license":"U"},"width":1242,"height":781},"alt":"Training log setting details"},"library":"H5P.Image 1.1","metadata":{"contentType":"Image","license":"U","title":"Untitled Image","defaultLanguage":"en"},"subContentId":"bde2a3c8-db3b-4186-9419-5417f2bce9c7"},"useSeparator":"auto"},{"content":{"params":{"contentName":"Image","file":{"path":"images\/file-61a5130697b99.png","mime":"image\/png","copyright":{"license":"U"},"width":1253,"height":751},"alt":"Training log dashboard"},"library":"H5P.Image 1.1","metadata":{"contentType":"Image","license":"U","title":"Untitled Image","defaultLanguage":"en"},"subContentId":"73c48db5-9980-4c47-8e11-b19f2e992e17"},"useSeparator":"auto"},{"content":{"params":{"contentName":"Image","file":{"path":"images\/file-61a5132280758.png","mime":"image\/png","copyright":{"license":"U"},"width":1253,"height":600},"alt":"Editing log details"},"library":"H5P.Image 1.1","metadata":{"contentType":"Image","license":"U","title":"Untitled Image","defaultLanguage":"en"},"subContentId":"4703e1b4-3a04-4514-ab21-ffc1e7809dc1"},"useSeparator":"auto"},{"content":{"params":{"media":{"disableImageZooming":false},"solution":{"introduction":"","sample":""},"keywords":[{"options":{"points":1,"occurrences":1,"caseSensitive":true,"forgiveMistakes":false,"feedbackIncludedWord":"keyword","feedbackMissedWord":"none"}}],"overallFeedback":[{"from":0,"to":100}],"behaviour":{"inputFieldSize":"10","enableRetry":true,"ignoreScoring":false,"pointsHost":1},"checkAnswer":"Check","tryAgain":"Retry","showSolution":"Show solution","feedbackHeader":"Feedback","solutionTitle":"Sample solution","remainingChars":"Remaining characters: @chars","notEnoughChars":"You must enter at least @chars characters!","messageSave":"saved","ariaYourResult":"You got @score out of @total points","ariaNavigatedToSolution":"Navigated to newly included sample solution after textarea.","taskDescription":"<p dir=\"ltr\">Pay attention to all details in the training log, are you able to answer these questions?<\/p>\n\n<p>&nbsp;<\/p>\n\n<ul>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">For how long exactly did the engine train?&nbsp;<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">How many bulbs were consumed to train it?<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">What was the BLEU score at step 10?&nbsp;<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">How many epochs did the training process complete? Why is it different from the number of epochs set in the parameters?<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Are BLEU scores higher or lower for the test set compared to validation?<\/p>\n\t<\/li>\n\t<li aria-level=\"1\" dir=\"ltr\">\n\t<p dir=\"ltr\" role=\"presentation\">Do you think that the system would still be able to get better if we let it keep training, how much better and how much time?<\/p>\n\t<\/li>\n<\/ul>\n"},"library":"H5P.Essay 1.2","metadata":{"contentType":"Essay","license":"U","title":"Untitled Essay","defaultLanguage":"en"},"subContentId":"fbc90408-b2c2-46ef-930d-b4f67d740d23"},"useSeparator":"auto"},{"content":{"params":{"text":"<p>Congrats, you\u2019ve completed a full training of a custom NMT system and you know a lot about how training works! You will now find this engine available at MutNMT on the Engines section. If you were not able to train, it will anyway be available as a Public Engine so you can grab it to get it active in Your engines section. Some details are provided in the engines list and some others in the three dots menu next to it. Using the menu, you will always be able to take a look at training logs, get translation models, the corpora used to train them and some other housekeeping actions.<\/p>\n"},"library":"H5P.AdvancedText 1.1","metadata":{"contentType":"Text","license":"U","title":"Untitled Text","defaultLanguage":"en"},"subContentId":"7c23d4f3-1ba3-41ed-9c5a-deb2a33ecaa1"},"useSeparator":"auto"}]}